{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogLeNet (Inception V1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I have implemented GoogLeNet (Inception V1) on dataset CIFAR-10 and CIFAR-100.\n",
    "Auxiliary classification used (exact model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!pip install keras\n",
    "import keras\n",
    "from keras.datasets import cifar10, cifar100\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Add, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(X, f1, f2_in, f2_out, f3_in, f3_out, f4_out, stage, block):\n",
    "    \n",
    "    name_sb = str(stage) + str(block)\n",
    "    \n",
    "    # 1x1 conv\n",
    "    conv1 = Conv2D(f1, (1,1), padding='same', activation='relu', name = 'conv_tower1_' + name_sb)(X)\n",
    "    # 3x3 conv\n",
    "    conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu', name = 'conv_tower2_1_' + name_sb)(X)\n",
    "    conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu', name = 'conv_tower2_2' + name_sb)(conv3)\n",
    "    # 5x5 conv\n",
    "    conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu', name = 'conv_tower3_1_' + name_sb)(X)\n",
    "    conv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu', name = 'conv_tower3_2_' + name_sb)(conv5)\n",
    "    # 3x3 max pooling\n",
    "    pool = MaxPooling2D((3,3), strides=(1,1), padding='same', name = 'mpool_tower4_' + name_sb)(X)\n",
    "    pool = Conv2D(f4_out, (1,1), padding='same', activation='relu', name = 'conv_tower4_' + name_sb)(pool)\n",
    "    \n",
    "    # concatenate filters\n",
    "    layer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
    "    \n",
    "    return layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auxiliary(x, classes, name=None):\n",
    "    \n",
    "    layer = AveragePooling2D(pool_size=(5,5), strides=3, padding='valid')(x)\n",
    "    layer = Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(units=256, activation='relu')(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "    layer = Dense(units=classes, activation='softmax', name=name)(layer)\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def googlenet(input_shape, classes):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(32, (3, 3), strides = (2, 2), name = 'conv_pre_inception_1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_pre_inception_1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides=(1, 1), name = 'mpool_pre_inception_1')(X)\n",
    "    \n",
    "    # Stage 2\n",
    "    X = Conv2D(192, (3, 3), strides = (1, 1), name = 'conv_pre_inception_2', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_pre_inception_2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(192, (3, 3), strides = (1, 1), name = 'conv_pre_inception_3', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_pre_inception_3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides=(1, 1), name = 'mpool_pre_inception_2')(X)\n",
    "    \n",
    "    # Stage 3\n",
    "    X = inception_module(X, 64, 96, 128, 16, 32, 32, 3, 'a')\n",
    "    X = inception_module(X, 128, 128, 192, 32, 96, 64, 3, 'b')\n",
    "    X = MaxPooling2D((2, 2), strides=(1, 1), name = 'mpool_inception_3')(X)\n",
    "    \n",
    "    # Stage 4\n",
    "    X = inception_module(X, 192, 96, 208, 16, 48, 64, 4, 'a')\n",
    "    aux1  = auxiliary(X, classes, name='aux1')\n",
    "    X = inception_module(X, 160, 112, 224, 24, 64, 64, 4, 'b')\n",
    "    X = inception_module(X, 128, 128, 256, 24, 24, 64, 4, 'c')\n",
    "    X = inception_module(X, 112, 144, 288, 32, 64, 64, 4, 'd')\n",
    "    aux2  = auxiliary(X, classes, name='aux2')\n",
    "    X = inception_module(X, 256, 120, 320, 32, 128, 128, 4, 'e')\n",
    "    X = MaxPooling2D((2, 2), strides=(1, 1), name = 'mpool_inception_4')(X)\n",
    "    \n",
    "    # Stage 5\n",
    "    X = inception_module(X, 256, 160, 320, 32, 128, 128, 5, 'a')\n",
    "    X = inception_module(X, 384, 192, 384, 48, 128, 128, 5, 'b')\n",
    "    X = AveragePooling2D((7, 7), strides=(1, 1), name = 'apool_inception_5')(X)\n",
    "    \n",
    "    # Stage 6\n",
    "    X = Dropout(0.4)(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1000, activation='relu', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    main = Dense(classes, activation='softmax', name='main', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    aux1 = keras.layers.Lambda(lambda x: x * 0.3)(aux1)                                         # Method 1\n",
    "    aux2 = keras.layers.Lambda(lambda x: x * 0.3)(aux2)                                         # Method 1\n",
    "    totalloss = keras.layers.Add()([aux1, aux2, main])                                          # Method 1\n",
    "    inceptionv1 = Model(inputs = X_input, outputs = [totalloss], name='InceptionV1')            # Method 1\n",
    "    #inceptionv1 = Model(inputs = X_input, outputs = [main, aux1, aux2], name='InceptionV1')    # Method 2\n",
    "\n",
    "    return inceptionv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "(c10_x_train, c10_y_train), (c10_x_test, c10_y_test) = cifar10.load_data()\n",
    "\n",
    "# Hyper-parameters\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "input_shape = c10_x_train.shape[1:]\n",
    "\n",
    "# Pre-processing\n",
    "c10_x_train = c10_x_train.astype('float32')\n",
    "c10_x_test = c10_x_test.astype('float32')\n",
    "c10_x_train = c10_x_train/255\n",
    "c10_x_test = c10_x_test/255\n",
    "c10_y_train = keras.utils.to_categorical(c10_y_train, num_classes)\n",
    "c10_y_test = keras.utils.to_categorical(c10_y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"InceptionV1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 38, 38, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_pre_inception_1 (Conv2D)   (None, 18, 18, 32)   896         zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn_pre_inception_1 (BatchNormal (None, 18, 18, 32)   128         conv_pre_inception_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 18, 18, 32)   0           bn_pre_inception_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "mpool_pre_inception_1 (MaxPooli (None, 17, 17, 32)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pre_inception_2 (Conv2D)   (None, 15, 15, 192)  55488       mpool_pre_inception_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn_pre_inception_2 (BatchNormal (None, 15, 15, 192)  768         conv_pre_inception_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 15, 15, 192)  0           bn_pre_inception_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_pre_inception_3 (Conv2D)   (None, 13, 13, 192)  331968      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_pre_inception_3 (BatchNormal (None, 13, 13, 192)  768         conv_pre_inception_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 13, 13, 192)  0           bn_pre_inception_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "mpool_pre_inception_2 (MaxPooli (None, 12, 12, 192)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_1_3a (Conv2D)       (None, 12, 12, 96)   18528       mpool_pre_inception_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_1_3a (Conv2D)       (None, 12, 12, 16)   3088        mpool_pre_inception_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "mpool_tower4_3a (MaxPooling2D)  (None, 12, 12, 192)  0           mpool_pre_inception_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower1_3a (Conv2D)         (None, 12, 12, 64)   12352       mpool_pre_inception_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_23a (Conv2D)        (None, 12, 12, 128)  110720      conv_tower2_1_3a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_2_3a (Conv2D)       (None, 12, 12, 32)   12832       conv_tower3_1_3a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower4_3a (Conv2D)         (None, 12, 12, 32)   6176        mpool_tower4_3a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 256)  0           conv_tower1_3a[0][0]             \n",
      "                                                                 conv_tower2_23a[0][0]            \n",
      "                                                                 conv_tower3_2_3a[0][0]           \n",
      "                                                                 conv_tower4_3a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_1_3b (Conv2D)       (None, 12, 12, 128)  32896       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_1_3b (Conv2D)       (None, 12, 12, 32)   8224        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mpool_tower4_3b (MaxPooling2D)  (None, 12, 12, 256)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower1_3b (Conv2D)         (None, 12, 12, 128)  32896       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_23b (Conv2D)        (None, 12, 12, 192)  221376      conv_tower2_1_3b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_2_3b (Conv2D)       (None, 12, 12, 96)   76896       conv_tower3_1_3b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower4_3b (Conv2D)         (None, 12, 12, 64)   16448       mpool_tower4_3b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 12, 12, 480)  0           conv_tower1_3b[0][0]             \n",
      "                                                                 conv_tower2_23b[0][0]            \n",
      "                                                                 conv_tower3_2_3b[0][0]           \n",
      "                                                                 conv_tower4_3b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mpool_inception_3 (MaxPooling2D (None, 11, 11, 480)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_1_4a (Conv2D)       (None, 11, 11, 96)   46176       mpool_inception_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_1_4a (Conv2D)       (None, 11, 11, 16)   7696        mpool_inception_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mpool_tower4_4a (MaxPooling2D)  (None, 11, 11, 480)  0           mpool_inception_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower1_4a (Conv2D)         (None, 11, 11, 192)  92352       mpool_inception_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_24a (Conv2D)        (None, 11, 11, 208)  179920      conv_tower2_1_4a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_2_4a (Conv2D)       (None, 11, 11, 48)   19248       conv_tower3_1_4a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower4_4a (Conv2D)         (None, 11, 11, 64)   30784       mpool_tower4_4a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 11, 11, 512)  0           conv_tower1_4a[0][0]             \n",
      "                                                                 conv_tower2_24a[0][0]            \n",
      "                                                                 conv_tower3_2_4a[0][0]           \n",
      "                                                                 conv_tower4_4a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_1_4b (Conv2D)       (None, 11, 11, 112)  57456       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_1_4b (Conv2D)       (None, 11, 11, 24)   12312       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mpool_tower4_4b (MaxPooling2D)  (None, 11, 11, 512)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower1_4b (Conv2D)         (None, 11, 11, 160)  82080       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_24b (Conv2D)        (None, 11, 11, 224)  226016      conv_tower2_1_4b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_2_4b (Conv2D)       (None, 11, 11, 64)   38464       conv_tower3_1_4b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower4_4b (Conv2D)         (None, 11, 11, 64)   32832       mpool_tower4_4b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 11, 11, 512)  0           conv_tower1_4b[0][0]             \n",
      "                                                                 conv_tower2_24b[0][0]            \n",
      "                                                                 conv_tower3_2_4b[0][0]           \n",
      "                                                                 conv_tower4_4b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_1_4c (Conv2D)       (None, 11, 11, 128)  65664       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_1_4c (Conv2D)       (None, 11, 11, 24)   12312       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mpool_tower4_4c (MaxPooling2D)  (None, 11, 11, 512)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower1_4c (Conv2D)         (None, 11, 11, 128)  65664       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_24c (Conv2D)        (None, 11, 11, 256)  295168      conv_tower2_1_4c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_2_4c (Conv2D)       (None, 11, 11, 24)   14424       conv_tower3_1_4c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower4_4c (Conv2D)         (None, 11, 11, 64)   32832       mpool_tower4_4c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 11, 11, 472)  0           conv_tower1_4c[0][0]             \n",
      "                                                                 conv_tower2_24c[0][0]            \n",
      "                                                                 conv_tower3_2_4c[0][0]           \n",
      "                                                                 conv_tower4_4c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_1_4d (Conv2D)       (None, 11, 11, 144)  68112       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_1_4d (Conv2D)       (None, 11, 11, 32)   15136       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mpool_tower4_4d (MaxPooling2D)  (None, 11, 11, 472)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower1_4d (Conv2D)         (None, 11, 11, 112)  52976       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_24d (Conv2D)        (None, 11, 11, 288)  373536      conv_tower2_1_4d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_2_4d (Conv2D)       (None, 11, 11, 64)   51264       conv_tower3_1_4d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower4_4d (Conv2D)         (None, 11, 11, 64)   30272       mpool_tower4_4d[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 11, 11, 528)  0           conv_tower1_4d[0][0]             \n",
      "                                                                 conv_tower2_24d[0][0]            \n",
      "                                                                 conv_tower3_2_4d[0][0]           \n",
      "                                                                 conv_tower4_4d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_1_4e (Conv2D)       (None, 11, 11, 120)  63480       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_1_4e (Conv2D)       (None, 11, 11, 32)   16928       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mpool_tower4_4e (MaxPooling2D)  (None, 11, 11, 528)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower1_4e (Conv2D)         (None, 11, 11, 256)  135424      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_24e (Conv2D)        (None, 11, 11, 320)  345920      conv_tower2_1_4e[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_2_4e (Conv2D)       (None, 11, 11, 128)  102528      conv_tower3_1_4e[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower4_4e (Conv2D)         (None, 11, 11, 128)  67712       mpool_tower4_4e[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 11, 11, 832)  0           conv_tower1_4e[0][0]             \n",
      "                                                                 conv_tower2_24e[0][0]            \n",
      "                                                                 conv_tower3_2_4e[0][0]           \n",
      "                                                                 conv_tower4_4e[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mpool_inception_4 (MaxPooling2D (None, 10, 10, 832)  0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_1_5a (Conv2D)       (None, 10, 10, 160)  133280      mpool_inception_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_1_5a (Conv2D)       (None, 10, 10, 32)   26656       mpool_inception_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mpool_tower4_5a (MaxPooling2D)  (None, 10, 10, 832)  0           mpool_inception_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower1_5a (Conv2D)         (None, 10, 10, 256)  213248      mpool_inception_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_25a (Conv2D)        (None, 10, 10, 320)  461120      conv_tower2_1_5a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_2_5a (Conv2D)       (None, 10, 10, 128)  102528      conv_tower3_1_5a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower4_5a (Conv2D)         (None, 10, 10, 128)  106624      mpool_tower4_5a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 10, 10, 832)  0           conv_tower1_5a[0][0]             \n",
      "                                                                 conv_tower2_25a[0][0]            \n",
      "                                                                 conv_tower3_2_5a[0][0]           \n",
      "                                                                 conv_tower4_5a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_1_5b (Conv2D)       (None, 10, 10, 192)  159936      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_1_5b (Conv2D)       (None, 10, 10, 48)   39984       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mpool_tower4_5b (MaxPooling2D)  (None, 10, 10, 832)  0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower1_5b (Conv2D)         (None, 10, 10, 384)  319872      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower2_25b (Conv2D)        (None, 10, 10, 384)  663936      conv_tower2_1_5b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower3_2_5b (Conv2D)       (None, 10, 10, 128)  153728      conv_tower3_1_5b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower4_5b (Conv2D)         (None, 10, 10, 128)  106624      mpool_tower4_5b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 10, 10, 1024) 0           conv_tower1_5b[0][0]             \n",
      "                                                                 conv_tower2_25b[0][0]            \n",
      "                                                                 conv_tower3_2_5b[0][0]           \n",
      "                                                                 conv_tower4_5b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 3, 3, 512)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 3, 3, 528)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "apool_inception_5 (AveragePooli (None, 4, 4, 1024)   0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 3, 3, 128)    65664       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 3, 3, 128)    67712       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 4, 4, 1024)   0           apool_inception_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1152)         0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1152)         0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 16384)        0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          295168      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          295168      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1000)         16385000    flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main (Dense)                    (None, 10)           10010       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "aux1 (Dense)                    (None, 10)           2570        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aux2 (Dense)                    (None, 10)           2570        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,188,534\n",
      "Trainable params: 23,187,702\n",
      "Non-trainable params: 832\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "googlenet = googlenet(input_shape, num_classes)\n",
    "googlenet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "googlenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 1.5870 - accuracy: 0.4073\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 1.1537 - accuracy: 0.5845\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 79s 2ms/step - loss: 0.9391 - accuracy: 0.6674\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.8034 - accuracy: 0.7172\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.6925 - accuracy: 0.7590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f7cd486bfd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googlenet.fit(c10_x_train, c10_y_train, epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 775us/step\n",
      "Test loss: 0.8266890961647033\n",
      "Test accuracy: 0.7185999751091003\n"
     ]
    }
   ],
   "source": [
    "scores = googlenet.evaluate(c10_x_test, c10_y_test)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.6179 - accuracy: 0.7874\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.5523 - accuracy: 0.8084\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.4892 - accuracy: 0.8286\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.4332 - accuracy: 0.8499\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.3976 - accuracy: 0.8599\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.3588 - accuracy: 0.8751\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.3229 - accuracy: 0.8870\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.2807 - accuracy: 0.9018\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.2671 - accuracy: 0.9063\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.2449 - accuracy: 0.9148 2s - loss:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f7cd48464a8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googlenet.fit(c10_x_train, c10_y_train, epochs = 10, batch_size = 128) # Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 726us/step\n",
      "Test loss: 0.7769441133975983\n",
      "Test accuracy: 0.7865999937057495\n"
     ]
    }
   ],
   "source": [
    "scores = googlenet.evaluate(c10_x_test, c10_y_test)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.2256 - accuracy: 0.9201\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.2094 - accuracy: 0.9267\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.1870 - accuracy: 0.9337\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.1876 - accuracy: 0.9329\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.1561 - accuracy: 0.9449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f7e784e2c50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googlenet.fit(c10_x_train, c10_y_train, epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 720us/step\n",
      "Test loss: 0.9074650887966156\n",
      "Test accuracy: 0.7718999981880188\n"
     ]
    }
   ],
   "source": [
    "scores = googlenet.evaluate(c10_x_test, c10_y_test)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 96s 2ms/step - loss: 4.7755 - main_loss: 1.6491 - aux1_loss: 1.5289 - aux2_loss: 1.5958 - main_accuracy: 0.3742 - aux1_accuracy: 0.4290 - aux2_accuracy: 0.3979\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 3.4071 - main_loss: 1.1734 - aux1_loss: 1.0927 - aux2_loss: 1.1404 - main_accuracy: 0.5768 - aux1_accuracy: 0.6077 - aux2_accuracy: 0.5896\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 2.7062 - main_loss: 0.9280 - aux1_loss: 0.8675 - aux2_loss: 0.9103 - main_accuracy: 0.6721 - aux1_accuracy: 0.6942 - aux2_accuracy: 0.6809: 8s - loss: 2.7250 - main_loss: 0.9349 - aux1_loss: 0.8740 - aux2_loss: 0.9162 - main_accuracy: 0.6684 - aux1_accuracy: 0.690 - ETA: 3s - loss: 2.7182 - main_loss: 0.9326 - aux1_loss: 0.8716 - aux2_loss: 0.9139 - main_accuracy: 0.6701 - aux1_accuracy: 0.6926 - aux\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 2.2918 - main_loss: 0.7894 - aux1_loss: 0.7309 - aux2_loss: 0.7710 - main_accuracy: 0.7246 - aux1_accuracy: 0.7449 - aux2_accuracy: 0.7331: 26s - loss: 2.3092 - main_loss: 0.7943 - aux1_loss: 0.7378 - aux - ETA: 17s - loss: 2.3140 - main_\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 1.9733 - main_loss: 0.6809 - aux1_loss: 0.6288 - aux2_loss: 0.6636 - main_accuracy: 0.7642 - aux1_accuracy: 0.7837 - aux2_accuracy: 0.7707\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 1.6929 - main_loss: 0.5819 - aux1_loss: 0.5428 - aux2_loss: 0.5690 - main_accuracy: 0.8013 - aux1_accuracy: 0.8129 - aux2_accuracy: 0.8060\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 1.4700 - main_loss: 0.5037 - aux1_loss: 0.4728 - aux2_loss: 0.4937 - main_accuracy: 0.8259 - aux1_accuracy: 0.8370 - aux2_accuracy: 0.8319\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 1.3089 - main_loss: 0.4513 - aux1_loss: 0.4200 - aux2_loss: 0.4374 - main_accuracy: 0.8464 - aux1_accuracy: 0.8553 - aux2_accuracy: 0.8526\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 1.1596 - main_loss: 0.4012 - aux1_loss: 0.3712 - aux2_loss: 0.3871 - main_accuracy: 0.8611 - aux1_accuracy: 0.8719 - aux2_accuracy: 0.8677\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 1.0067 - main_loss: 0.3493 - aux1_loss: 0.3212 - aux2_loss: 0.3363 - main_accuracy: 0.8796 - aux1_accuracy: 0.8881 - aux2_accuracy: 0.8839\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.8691 - main_loss: 0.3001 - aux1_loss: 0.2793 - aux2_loss: 0.2898 - main_accuracy: 0.8962 - aux1_accuracy: 0.9045 - aux2_accuracy: 0.9003\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.7769 - main_loss: 0.2716 - aux1_loss: 0.2452 - aux2_loss: 0.2606 - main_accuracy: 0.9059 - aux1_accuracy: 0.9147 - aux2_accuracy: 0.9114\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.6970 - main_loss: 0.2451 - aux1_loss: 0.2196 - aux2_loss: 0.2322 - main_accuracy: 0.9155 - aux1_accuracy: 0.9250 - aux2_accuracy: 0.9206\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.5987 - main_loss: 0.2120 - aux1_loss: 0.1895 - aux2_loss: 0.1979 - main_accuracy: 0.9266 - aux1_accuracy: 0.9342 - aux2_accuracy: 0.9314\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.5554 - main_loss: 0.1972 - aux1_loss: 0.1748 - aux2_loss: 0.1837 - main_accuracy: 0.9328 - aux1_accuracy: 0.9403 - aux2_accuracy: 0.9377\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.4989 - main_loss: 0.1774 - aux1_loss: 0.1551 - aux2_loss: 0.1667 - main_accuracy: 0.9377 - aux1_accuracy: 0.9458 - aux2_accuracy: 0.9426\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.4335 - main_loss: 0.1546 - aux1_loss: 0.1354 - aux2_loss: 0.1437 - main_accuracy: 0.9456 - aux1_accuracy: 0.9539 - aux2_accuracy: 0.9510: 18s - loss: 0.4161 - main_loss: 0.1484 - aux1_loss: 0.1295 - aux2_loss: 0.1382 - main_accuracy: 0.9477 - aux1_accuracy: 0.9560 - ETA: 16s - loss: 0.4198 - main_loss: 0.1496 - aux1_loss: 0.1309 - - ETA: 3s - loss: 0.4282 - main_loss: 0.1527 - aux1_loss: 0.1338 - aux2_loss: 0.1417 - main_accuracy: 0.9463 - aux1_accuracy: 0.9543 - aux2_accuracy: - ETA: 2s - loss: 0.4313 - main_loss: 0.1536 - aux1_loss: 0.1349 - aux2_loss: 0.1427 - main_accuracy: 0.9460 - aux1_accuracy: 0.9539 - aux2_accur\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.3838 - main_loss: 0.1362 - aux1_loss: 0.1212 - aux2_loss: 0.1264 - main_accuracy: 0.9540 - aux1_accuracy: 0.9586 - aux2_accuracy: 0.9574\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.3572 - main_loss: 0.1286 - aux1_loss: 0.1100 - aux2_loss: 0.1188 - main_accuracy: 0.9563 - aux1_accuracy: 0.9619 - aux2_accuracy: 0.9591: 2s - loss: 0.3560 - main_loss: 0.1283 - aux1_loss: 0.1095 - aux2_loss: 0.1182 - main_accuracy: 0.9565 - aux1_accuracy: 0.9621 - aux2_accu\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.3403 - main_loss: 0.1233 - aux1_loss: 0.1048 - aux2_loss: 0.1122 - main_accuracy: 0.9581 - aux1_accuracy: 0.9645 - aux2_accuracy: 0.9630\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.2972 - main_loss: 0.1072 - aux1_loss: 0.0914 - aux2_loss: 0.0988 - main_accuracy: 0.9627 - aux1_accuracy: 0.9692 - aux2_accuracy: 0.9665: 13s - loss: 0.2911 - main_loss: 0.1044 - aux1_loss: 0.0895 - aux2_lo\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.3052 - main_loss: 0.1101 - aux1_loss: 0.0946 - aux2_loss: 0.1008 - main_accuracy: 0.9622 - aux1_accuracy: 0.9677 - aux2_accuracy: 0.9655\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.2691 - main_loss: 0.0968 - aux1_loss: 0.0839 - aux2_loss: 0.0888 - main_accuracy: 0.9674 - aux1_accuracy: 0.9717 - aux2_accuracy: 0.9705\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.2563 - main_loss: 0.0919 - aux1_loss: 0.0811 - aux2_loss: 0.0834 - main_accuracy: 0.9694 - aux1_accuracy: 0.9728 - aux2_accuracy: 0.9723\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.2421 - main_loss: 0.0886 - aux1_loss: 0.0742 - aux2_loss: 0.0795 - main_accuracy: 0.9700 - aux1_accuracy: 0.9745 - aux2_accuracy: 0.9743: 43s -  - ETA: 28s - loss: 0.2334 - main_loss: 0.0851 - aux1_loss: 0.0714 - aux2_loss: 0.0770 - main_\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f93d7762f98>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googlenet.fit(c10_x_train, [c10_y_train, c10_y_train, c10_y_train], epochs = 25, batch_size = 128)  # Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 9s 875us/step\n",
      "Test loss: 3.162414232349396\n",
      "Test accuracy: 1.0123772621154785\n"
     ]
    }
   ],
   "source": [
    "scores = googlenet.evaluate(c10_x_test, [c10_y_test, c10_y_test, c10_y_test])\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet.save('googlenet_c10.h5')\n",
    "googlenet.save_weights('googlenet_c10_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "(c100_x_train, c100_y_train), (c100_x_test, c100_y_test) = cifar100.load_data()\n",
    "\n",
    "# Hyper-parameters\n",
    "c100_epochs = 25\n",
    "c100_batch_size = 128\n",
    "c100_num_classes = 100\n",
    "c100_input_shape = c100_x_train.shape[1:]\n",
    "\n",
    "# Pre-processing\n",
    "c100_x_train = c100_x_train.astype('float32')\n",
    "c100_x_test = c100_x_test.astype('float32')\n",
    "c100_x_train = c100_x_train/255\n",
    "c100_x_test = c100_x_test/255\n",
    "c100_y_train = keras.utils.to_categorical(c100_y_train, c100_num_classes)\n",
    "c100_y_test = keras.utils.to_categorical(c100_y_test, c100_num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c100_googlenet = googlenet(input_shape = c100_input_shape, classes = c100_num_classes)\n",
    "c100_googlenet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#c100_googlenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.9787 - main_loss: 0.2493 - aux1_loss: 0.3613 - aux2_loss: 0.3684 - main_accuracy: 0.9199 - aux1_accuracy: 0.8816 - aux2_accuracy: 0.8828 - val_loss: 12.4432 - val_main_loss: 4.3773 - val_aux1_loss: 4.0579 - val_aux2_loss: 3.9761 - val_main_accuracy: 0.4004 - val_aux1_accuracy: 0.4138 - val_aux2_accuracy: 0.4062n_loss: 0.1937 - aux1_loss: 0.3122 - aux2_loss: 0.3079 - main_accuracy: 0.9373 - aux1_accuracy: 0.8975 - aux2_accura - ETA: 49s - loss: 0.8232 - main_loss: 0.1975 - aux1_loss: 0.3158 - aux2_loss: 0.3099 - main_accuracy: 0.9365 - aux1_accuracy: 0.8966 - a - ETA: 47s - loss: 0.8316 - main_loss: 0.2012 - aux1_loss: 0.3169 - aux2_loss: 0.3135 - main_accuracy: 0.9357 - aux1_accuracy: 0.8959 - aux2_ - ETA: 46s - loss: 0.8490 - main_loss: 0.2074 - aux1_loss: 0.3221 - aux2_loss: 0.3195 - main_accuracy: 0.9339 - aux1_accuracy: 0.8941 - aux2_accu - ETA: 44s - loss: 0.8527 - main_loss: 0.2088 - aux1_loss: 0.3231 - aux2_loss: 0.3209 - main_accuracy: 0.9334 - aux1_accuracy: 0.8936 - aux2_ - ETA: 43s - loss: 0.8634 - main_loss: 0.2130 - aux1_loss: 0.3264 - a - ETA: 34s - loss: \n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.9269 - main_loss: 0.2401 - aux1_loss: 0.3375 - aux2_loss: 0.3499 - main_accuracy: 0.9224 - aux1_accuracy: 0.8892 - aux2_accuracy: 0.8879 - val_loss: 10.5648 - val_main_loss: 3.6527 - val_aux1_loss: 3.3841 - val_aux2_loss: 3.4899 - val_main_accuracy: 0.4565 - val_aux1_accuracy: 0.4668 - val_aux2_accuracy: 0.4532s - loss: 0.8762 - main_loss: 0.2234 - aux1_loss: 0.3193 - aux2_loss: 0.3334 - main_accuracy:  - ETA: 13s - loss: 0.9049 - main_loss: 0.2326 - aux1_loss: 0.3307 - a\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.9271 - main_loss: 0.2400 - aux1_loss: 0.3395 - aux2_loss: 0.3475 - main_accuracy: 0.9235 - aux1_accuracy: 0.8883 - aux2_accuracy: 0.8885 - val_loss: 14.5864 - val_main_loss: 5.0640 - val_aux1_loss: 4.6556 - val_aux2_loss: 4.8414 - val_main_accuracy: 0.3859 - val_aux1_accuracy: 0.4007 - val_aux2_accuracy: 0.3943\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.9042 - main_loss: 0.2341 - aux1_loss: 0.3350 - aux2_loss: 0.3351 - main_accuracy: 0.9255 - aux1_accuracy: 0.8905 - aux2_accuracy: 0.8922 - val_loss: 10.4359 - val_main_loss: 3.5548 - val_aux1_loss: 3.4081 - val_aux2_loss: 3.4432 - val_main_accuracy: 0.4636 - val_aux1_accuracy: 0.4720 - val_aux2_accuracy: 0.4686ux2_loss: 0.3315 - main_accuracy: 0.9268 - aux1_accuracy: 0.8917 - aux2_a\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.8906 - main_loss: 0.2324 - aux1_loss: 0.3219 - aux2_loss: 0.3361 - main_accuracy: 0.9244 - aux1_accuracy: 0.8943 - aux2_accuracy: 0.8904 - val_loss: 11.2866 - val_main_loss: 3.7495 - val_aux1_loss: 3.7046 - val_aux2_loss: 3.7849 - val_main_accuracy: 0.4628 - val_aux1_accuracy: 0.4697 - val_aux2_accuracy: 0.4564s - loss: 0.8338 - main_loss: 0.2115 - aux1_loss: 0.3047 - aux2_loss: 0.3175 - main_accuracy: 0.9308 - - ETA: 22s - loss: 0.8433 - main_loss: 0.2141 - aux1_loss: 0.3062 - aux2_loss: 0.3229 - main_accuracy: 0.9302 - aux1_accuracy: 0.8991 - aux2_ - ETA: 20s - loss: 0.8489 - main_loss: 0.2169 - aux1_loss: 0.3077 - aux2_loss: 0.3242 - main_accuracy: 0.9296 - aux1_accuracy: 0.8985 - aux2_accuracy:  - ETA: 20s - loss: 0.8520 - main_loss: 0.2187 - aux1_loss: 0.3079 - aux2_loss: 0.3255 - main_accuracy: 0.9290 - aux1_accuracy: 0.8985 - aux2_accura - ETA: 19s - loss: 0.8537 - main_loss: 0.2202 - ETA: 6s - loss: 0.8826 - main_loss: 0.2315 - aux1_loss: 0.3170 - aux2_loss: 0.3341 - main_accuracy: 0.9251 - aux1_accuracy\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.8176 - main_loss: 0.2100 - aux1_loss: 0.3004 - aux2_loss: 0.3074 - main_accuracy: 0.9330 - aux1_accuracy: 0.9018 - aux2_accuracy: 0.9019 - val_loss: 10.9889 - val_main_loss: 3.6803 - val_aux1_loss: 3.6685 - val_aux2_loss: 3.6217 - val_main_accuracy: 0.4503 - val_aux1_accuracy: 0.4705 - val_aux2_accuracy: 0.45997027 - main_loss: 0.1 - ETA: 50s - loss: 0.7187 - main_loss: 0.1739 - aux1_loss: 0.2693 - aux2_loss: 0.2756 - main_ac - ETA: 44s - loss: 0.7221 - main_loss: 0.1767 - a - ETA: 33s - loss: 0.7429 - main_loss: 0.1847 - aux1_loss: 0.2760 - aux2_loss: 0.2821 - main_accuracy: 0.9415 - aux1_accuracy: 0.9089 - aux2_accu - ETA: 32s - loss: 0.7504 - main_loss: 0.1863 - aux1_loss: 0.2789 - aux2_loss: 0.2852 - main_accuracy: 0.9409 - aux1_accuracy: 0.9081 - aux2_accuracy:  - ETA: 31s - loss: 0.7511 - main_loss: 0.1869 - aux1_loss: 0.2793 - aux2_loss: 0.2849 - main_accuracy: 0.94 - ETA: 26s - loss: 0.7606 - main_loss: 0.1914 - aux1_loss: 0.2822 - aux2_loss: 0.2871 - main_accura\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.8386 - main_loss: 0.2219 - aux1_loss: 0.3042 - aux2_loss: 0.3127 - main_accuracy: 0.9290 - aux1_accuracy: 0.9006 - aux2_accuracy: 0.9016 - val_loss: 11.1229 - val_main_loss: 3.8150 - val_aux1_loss: 3.6766 - val_aux2_loss: 3.6016 - val_main_accuracy: 0.4609 - val_aux1_accuracy: 0.4718 - val_aux2_accuracy: 0.4584298 - aux1_accuracy: 0.9020 - a - ETA: 8s - loss: 0.8322 - main_loss: 0.2203 - aux1_loss: 0.3018 - aux2_loss: 0.3100 - main_accuracy: 0.9295 - aux\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.8265 - main_loss: 0.2153 - aux1_loss: 0.3052 - aux2_loss: 0.3062 - main_accuracy: 0.9315 - aux1_accuracy: 0.9010 - aux2_accuracy: 0.9025 - val_loss: 11.9568 - val_main_loss: 4.1509 - val_aux1_loss: 3.8799 - val_aux2_loss: 3.9068 - val_main_accuracy: 0.4489 - val_aux1_accuracy: 0.4581 - val_aux2_accuracy: 0.4491\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.8079 - main_loss: 0.2093 - aux1_loss: 0.3006 - aux2_loss: 0.2981 - main_accuracy: 0.9331 - aux1_accuracy: 0.9028 - aux2_accuracy: 0.9049 - val_loss: 11.6173 - val_main_loss: 3.8559 - val_aux1_loss: 3.8515 - val_aux2_loss: 3.9094 - val_main_accuracy: 0.4639 - val_aux1_accuracy: 0.4784 - val_aux2_accuracy: 0.4570\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 84s 2ms/step - loss: 0.7778 - main_loss: 0.2039 - aux1_loss: 0.2815 - aux2_loss: 0.2929 - main_accuracy: 0.9354 - aux1_accuracy: 0.9092 - aux2_accuracy: 0.9061 - val_loss: 11.5112 - val_main_loss: 3.9281 - val_aux1_loss: 3.7933 - val_aux2_loss: 3.7836 - val_main_accuracy: 0.4588 - val_aux1_accuracy: 0.4763 - val_aux2_accuracy: 0.4555\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.8224 - main_loss: 0.2153 - aux1_loss: 0.2966 - aux2_loss: 0.3104 - main_accuracy: 0.9311 - aux1_accuracy: 0.9020 - aux2_accuracy: 0.9014 - val_loss: 11.5570 - val_main_loss: 3.9207 - val_aux1_loss: 3.8452 - val_aux2_loss: 3.7555 - val_main_accuracy: 0.4659 - val_aux1_accuracy: 0.4741 - val_aux2_accuracy: 0.4604\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.7192 - main_loss: 0.1845 - aux1_loss: 0.2709 - aux2_loss: 0.2643 - main_accuracy: 0.9415 - aux1_accuracy: 0.9113 - aux2_accuracy: 0.9162 - val_loss: 12.8042 - val_main_loss: 4.3666 - val_aux1_loss: 4.0929 - val_aux2_loss: 4.3110 - val_main_accuracy: 0.4202 - val_aux1_accuracy: 0.4376 - val_aux2_accuracy: 0.4169\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.7476 - main_loss: 0.1891 - aux1_loss: 0.2782 - aux2_loss: 0.2809 - main_accuracy: 0.9387 - aux1_accuracy: 0.9114 - aux2_accuracy: 0.9117 - val_loss: 11.6865 - val_main_loss: 3.8712 - val_aux1_loss: 3.9739 - val_aux2_loss: 3.8139 - val_main_accuracy: 0.4572 - val_aux1_accuracy: 0.4691 - val_aux2_accuracy: 0.4542\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.7545 - main_loss: 0.2004 - aux1_loss: 0.2710 - aux2_loss: 0.2831 - main_accuracy: 0.9363 - aux1_accuracy: 0.9123 - aux2_accuracy: 0.9104 - val_loss: 11.7134 - val_main_loss: 3.8581 - val_aux1_loss: 4.0675 - val_aux2_loss: 3.7726 - val_main_accuracy: 0.4650 - val_aux1_accuracy: 0.4768 - val_aux2_accuracy: 0.4631oss: 0.1845 - aux1_l - ETA: 8s - loss: 0.7389 - main_loss: 0.1961 - aux1_loss: 0.2650 - aux2_loss: 0.2778 - main_accuracy: 0.9377 - aux1_accuracy: 0.9137 - aux2_ - ETA: 5s - loss: 0.7471 - main_loss: 0.1987 - aux1_loss: 0.2681 - aux2_loss: 0.2803 - main_accuracy: 0.9371 - aux1_accuracy: 0.9131 - aux2_accu - ETA: 2s - loss: 0.7498 - main_loss: 0.1994 - aux1_loss: 0.2692 - aux2_loss: 0.2812 - main_accuracy: 0.9368 - aux1_accuracy: 0.9126 - aux2_a\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.7292 - main_loss: 0.1865 - aux1_loss: 0.2709 - aux2_loss: 0.2717 - main_accuracy: 0.9394 - aux1_accuracy: 0.9119 - aux2_accuracy: 0.9137 - val_loss: 11.8792 - val_main_loss: 4.0209 - val_aux1_loss: 3.9295 - val_aux2_loss: 3.9265 - val_main_accuracy: 0.4662 - val_aux1_accuracy: 0.4774 - val_aux2_accuracy: 0.4654x1_loss: 0.2393 - aux2_ - ETA: 20s - loss: 0.7066 - main_loss: 0.1797 - aux1_loss: 0.2602 - aux2_ - ETA: 12s - loss: 0.7166 - main_loss: 0.1838 - aux1_loss: 0.2647 - aux2_loss: 0.2681  - ETA: 0s - loss: 0.7293 - main_loss: 0.1867 - aux1_loss: 0.2707 - aux2_loss: 0.2719 - main_accuracy: 0.9394 - aux1_accuracy: 0.9120 - aux2_accuracy: 0.913\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.7169 - main_loss: 0.1865 - aux1_loss: 0.2644 - aux2_loss: 0.2659 - main_accuracy: 0.9393 - aux1_accuracy: 0.9153 - aux2_accuracy: 0.9172 - val_loss: 11.7127 - val_main_loss: 3.8337 - val_aux1_loss: 4.0058 - val_aux2_loss: 3.8563 - val_main_accuracy: 0.4616 - val_aux1_accuracy: 0.4626 - val_aux2_accuracy: 0.4564cy: 0.9407 - aux1_accuracy: 0\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.6865 - main_loss: 0.1803 - aux1_loss: 0.2479 - aux2_loss: 0.2584 - main_accuracy: 0.9431 - aux1_accuracy: 0.9212 - aux2_accuracy: 0.9182 - val_loss: 12.1658 - val_main_loss: 3.9721 - val_aux1_loss: 4.2358 - val_aux2_loss: 3.9396 - val_main_accuracy: 0.4671 - val_aux1_accuracy: 0.4756 - val_aux2_accuracy: 0.4639- aux - ETA: 54s - loss: 0.6304 - main_loss: 0.1639 - aux1_loss: 0.2343 - aux2_loss: 0.2322 - main_accuracy: 0.9482 - aux1_accuracy: 0.9274 - aux2_accura - ETA: 53s - loss: 0.6346 - main_loss: 0.1645 - aux1_loss: 0.2361 - aux2_loss: 0.2339 - main_accuracy: 0.9481 - aux1_accuracy: 0.9265 - a - ETA: 51s - loss: 0.6354 - main_loss: 0.1660 - aux1_loss: 0.2354 - aux2_loss: 0.2341 - main_accuracy: 0.9476 - aux1_accuracy: 0.9265 - aux2_ - ETA: 49s - loss: 0.6338 - main_loss: 0.1667 - aux1_loss: 0.2322 - aux2_loss: 0.2349 - main_accuracy: 0.9472 - aux1_accuracy: 0.9275 - aux2_accuracy:  - ETA: 48s - loss: 0.6349 - main_loss: 0.1677 - aux1_loss: 0.2321 - aux2_loss: 0.2350 - main_accuracy: 0.9468 - aux1_accuracy: 0.9277 - aux2_accuracy:  - ETA: 48s - loss: 0.6336 - main_loss: 0.1669 - aux1_loss: 0.2320 - aux2_loss: 0.2347 - main_accuracy: 0.9470 - aux1_accuracy: 0.9277 - aux2_accuracy: 0. - ETA: 47s - loss: 0.6335 - main_loss: 0.1675 - aux1_loss: 0.2311 - aux2_loss: 0.2349 - main_accuracy: 0.9472 - aux1_ - ETA: 12s - loss: 0.6705 - main_loss: 0.1761 - aux1_loss: 0.2434 - aux2_loss: 0.2510 - main_accuracy: 0.9446 - aux1_accuracy: 0.9231 - a - ETA: 10s - loss: 0.6753 - main_loss: 0.1778 - aux1_loss: 0.2442 - aux2_loss: 0.2533 - main_accuracy: 0.\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.7068 - main_loss: 0.1867 - aux1_loss: 0.2564 - aux2_loss: 0.2636 - main_accuracy: 0.9409 - aux1_accuracy: 0.9177 - aux2_accuracy: 0.9169 - val_loss: 12.1216 - val_main_loss: 4.0407 - val_aux1_loss: 4.1559 - val_aux2_loss: 3.9262 - val_main_accuracy: 0.4503 - val_aux1_accuracy: 0.4641 - val_aux2_accuracy: 0.4575\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.6745 - main_loss: 0.1769 - aux1_loss: 0.2419 - aux2_loss: 0.2566 - main_accuracy: 0.9445 - aux1_accuracy: 0.9211 - aux2_accuracy: 0.9190 - val_loss: 12.4884 - val_main_loss: 4.0894 - val_aux1_loss: 4.3098 - val_aux2_loss: 4.0287 - val_main_accuracy: 0.4527 - val_aux1_accuracy: 0.4653 - val_aux2_accuracy: 0.4515393 - aux2_loss: 0.2534 - main_accuracy: 0.9449 - aux1_accuracy: 0.9217 - aux2_\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.6544 - main_loss: 0.1716 - aux1_loss: 0.2372 - aux2_loss: 0.2454 - main_accuracy: 0.9451 - aux1_accuracy: 0.9240 - aux2_accuracy: 0.9214 - val_loss: 12.5945 - val_main_loss: 4.0876 - val_aux1_loss: 4.4920 - val_aux2_loss: 3.9958 - val_main_accuracy: 0.4583 - val_aux1_accuracy: 0.4669 - val_aux2_accuracy: 0.4615loss: 0.2289 - aux2_loss: 0.2347 - main_accuracy: 0.9481 - aux1_accu - ETA: 17s - loss: 0.6235 - main_loss: 0.1615 - aux1_loss: 0.2272 - aux2_loss: 0.2349 - main_accuracy: 0.9482 - aux1_accuracy: 0.9261 - aux2_accuracy: 0. - ETA: 17s - loss: 0.6239 - main_lo\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.6306 - main_loss: 0.1597 - aux1_loss: 0.2378 - aux2_loss: 0.2331 - main_accuracy: 0.9500 - aux1_accuracy: 0.9247 - aux2_accuracy: 0.9256 - val_loss: 11.9779 - val_main_loss: 3.9083 - val_aux1_loss: 4.1431 - val_aux2_loss: 3.9042 - val_main_accuracy: 0.4670 - val_aux1_accuracy: 0.4760 - val_aux2_accuracy: 0.4641ccuracy: 0.9552 - aux1_accuracy: 0.9282 - a - ETA: 23s - ETA: 8s - loss: 0.6136 - main_loss: 0.1536 - aux1_loss: 0.2321 - aux2_loss: 0.2279 - main_accuracy: 0.9517 - au\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.6650 - main_loss: 0.1755 - aux1_loss: 0.2385 - aux2_loss: 0.2508 - main_accuracy: 0.9448 - aux1_accuracy: 0.9230 - aux2_accuracy: 0.9199 - val_loss: 12.4935 - val_main_loss: 4.0265 - val_aux1_loss: 4.3449 - val_aux2_loss: 4.1126 - val_main_accuracy: 0.4546 - val_aux1_accuracy: 0.4683 - val_aux2_accuracy: 0.4523s: 0.2325 - aux2_loss: 0.2437 - main_accuracy: 0.9459 - aux1_accuracy: 0.9241 - aux2_accuracy - ETA: 12s - loss: 0.6494 - main_loss: 0.1703 - aux1_loss: 0.2345 - aux2_loss: 0.24\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.6999 - main_loss: 0.1826 - aux1_loss: 0.2589 - aux2_loss: 0.2584 - main_accuracy: 0.9417 - aux1_accuracy: 0.9178 - aux2_accuracy: 0.9181 - val_loss: 13.6671 - val_main_loss: 4.2897 - val_aux1_loss: 4.8219 - val_aux2_loss: 4.5047 - val_main_accuracy: 0.4395 - val_aux1_accuracy: 0.4485 - val_aux2_accuracy: 0.44003 - aux2_loss: 0.2356 - main_accuracy: 0.9478 - aux1_accuracy - ETA: 26 - ETA: 11s - loss: 0.6824 - main_loss: 0.1769 - aux1_loss: 0.2511 - aux2_loss: 0.2543 - main_\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.6429 - main_loss: 0.1658 - aux1_loss: 0.2391 - aux2_loss: 0.2384 - main_accuracy: 0.9472 - aux1_accuracy: 0.9248 - aux2_accuracy: 0.9260 - val_loss: 12.9127 - val_main_loss: 4.1883 - val_aux1_loss: 4.4596 - val_aux2_loss: 4.2426 - val_main_accuracy: 0.4489 - val_aux1_accuracy: 0.4630 - val_aux2_accuracy: 0.4472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4c647aa9b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 1\n",
    "c100_googlenet.fit(c100_x_train, [c100_y_train, c100_y_train, c100_y_train], validation_data=(c100_x_test, [c100_y_test, c100_y_test, c100_y_test]), epochs = c100_epochs, batch_size = c100_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 640us/step\n",
      "Test loss: 12.912689134216308\n",
      "Test accuracy: 4.190948486328125\n"
     ]
    }
   ],
   "source": [
    "scores = c100_googlenet.evaluate(c100_x_test, [c100_y_test, c100_y_test, c100_y_test])\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c100_googlenet.save('googlenet_c100.h5')\n",
    "c100_googlenet.save_weights('googlenet_c100_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 4.0550 - accuracy: 0.0753\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 3.5255 - accuracy: 0.1527\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 3.1837 - accuracy: 0.2131\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 2.8986 - accuracy: 0.2655\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 2.6458 - accuracy: 0.3131\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 2.4445 - accuracy: 0.3518\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 2.2635 - accuracy: 0.3918\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 2.1202 - accuracy: 0.4225\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.9820 - accuracy: 0.4530\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.8532 - accuracy: 0.4862\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.7309 - accuracy: 0.5144\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.6268 - accuracy: 0.5387\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.5389 - accuracy: 0.5606\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.4432 - accuracy: 0.5842\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.3662 - accuracy: 0.6044\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.2825 - accuracy: 0.6244\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.2040 - accuracy: 0.6452\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.1562 - accuracy: 0.6572\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.0948 - accuracy: 0.6721\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.0372 - accuracy: 0.6889\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.9770 - accuracy: 0.7042\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.9404 - accuracy: 0.7153\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.8911 - accuracy: 0.7294\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.8527 - accuracy: 0.7411\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.8355 - accuracy: 0.7467A: 13s - loss: 0.8274 - accuracy: 0.7 - ETA: 12s - loss: 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4c5c2ddef0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c100_googlenet.fit(c100_x_train, c100_y_train, epochs = c100_epochs, batch_size = c100_batch_size) # Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 621us/step\n",
      "Test loss: 2.4383833072662355\n",
      "Test accuracy: 0.454800009727478\n"
     ]
    }
   ],
   "source": [
    "scores = c100_googlenet.evaluate(c100_x_test, c100_y_test)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
